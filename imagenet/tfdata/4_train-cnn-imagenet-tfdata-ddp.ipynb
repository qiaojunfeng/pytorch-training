{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a4f276-6634-4387-8b5b-6704d9500888",
   "metadata": {},
   "source": [
    "# Basic training on multiple GPUs of a CNN on imagenet from tfrecord files using TensorFlow's `tf.data` API\n",
    "\n",
    "Here we will run a simplified training loop for a CNN model on ImageNet. We will create a TensorFlow's [`tf.data` API](https://www.tensorflow.org/guide/data) input pipeline based to feed to model with ImageNet data stored in tfrecord files.\n",
    "\n",
    "We use [TensorFlow Datasets](https://www.tensorflow.org/datasets) to convert a `tf.data.Dataset` dataset to an iterable of NumPy arrays:\n",
    "```python\n",
    "np_dataset = tfds.as_numpy(tf_dataset)\n",
    "```\n",
    "from which the data is converted to `torch.tensor` and then moved to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd54a174-888a-49b3-995a-9c7adf97872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipcmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d8e78c-1608-4118-96ca-0f3e62469e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:09<00:00,  4.56s/engine]\n"
     ]
    }
   ],
   "source": [
    "%ipcluster start -n 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e943cb-4442-4ebd-839a-e99968167109",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pxconfig --progress-after -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2363679-29a4-402d-bc2c-9cd31fe0944f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stderr:0] 2022-10-12 10:29:48.335462: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
       "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
       "2022-10-12 10:29:48.489707: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
       "2022-10-12 10:29:49.467117: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/daint/UES/6.0.UP04/sandboxes/sarafael/software/cuDNN/8.1.0/lib:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/compat:/usr/local/cuda-11.3/compat:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/math_libs/11.3/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/extras/CUPTI/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/extras/Debugger/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/nvvm/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/lib64:/usr/local/cuda-11.0/lib64:/opt/cray/pe/mpt/7.7.18/gni/mpich-gnu/8.2/lib:/opt/cray/pe/perftools/21.09.0/lib64:/opt/cray/rca/2.2.20-7.0.3.1_3.15__g8e3fb5b.ari/lib64:/opt/cray/pe/pmi/5.0.17/lib64:/opt/cray/pe/libsci/20.09.1/GNU/8.1/x86_64/lib:/apps/daint/UES/jenkins/7.0.UP03/21.09/daint-gpu/software/graphviz/2.50.0-CrayGNU-21.09/lib:/opt/cray/pe/libsci_acc/20.10.1/GNU/8.1/x86_64/lib:/apps/daint/UES/jenkins/7.0.UP03/21.09/daint-gpu/software/Julia/1.6.3-CrayGNU-21.09-cuda/lib:/opt/python/3.9.4.1/lib:/opt/cray/pe/gcc-libs:/opt/cray/pe/papi/6.0.0.9/lib64:/opt/gcc/9.3.0/snos/lib64\n",
       "2022-10-12 10:29:49.467300: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/daint/UES/6.0.UP04/sandboxes/sarafael/software/cuDNN/8.1.0/lib:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/compat:/usr/local/cuda-11.3/compat:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/math_libs/11.3/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/extras/CUPTI/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/extras/Debugger/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/nvvm/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/lib64:/usr/local/cuda-11.0/lib64:/opt/cray/pe/mpt/7.7.18/gni/mpich-gnu/8.2/lib:/opt/cray/pe/perftools/21.09.0/lib64:/opt/cray/rca/2.2.20-7.0.3.1_3.15__g8e3fb5b.ari/lib64:/opt/cray/pe/pmi/5.0.17/lib64:/opt/cray/pe/libsci/20.09.1/GNU/8.1/x86_64/lib:/apps/daint/UES/jenkins/7.0.UP03/21.09/daint-gpu/software/graphviz/2.50.0-CrayGNU-21.09/lib:/opt/cray/pe/libsci_acc/20.10.1/GNU/8.1/x86_64/lib:/apps/daint/UES/jenkins/7.0.UP03/21.09/daint-gpu/software/Julia/1.6.3-CrayGNU-21.09-cuda/lib:/opt/python/3.9.4.1/lib:/opt/cray/pe/gcc-libs:/opt/cray/pe/papi/6.0.0.9/lib64:/opt/gcc/9.3.0/snos/lib64\n",
       "2022-10-12 10:29:49.467312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
       "/apps/daint/UES/6.0.UP04/sandboxes/sarafael/hpcpython2022/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
       "  from .autonotebook import tqdm as notebook_tqdm\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stderr:1] 2022-10-12 10:29:48.508854: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
       "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
       "2022-10-12 10:29:48.938998: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
       "2022-10-12 10:29:51.339906: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/daint/UES/6.0.UP04/sandboxes/sarafael/software/cuDNN/8.1.0/lib:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/compat:/usr/local/cuda-11.3/compat:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/math_libs/11.3/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/extras/CUPTI/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/extras/Debugger/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/nvvm/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/lib64:/usr/local/cuda-11.0/lib64:/opt/cray/pe/mpt/7.7.18/gni/mpich-gnu/8.2/lib:/opt/cray/pe/perftools/21.09.0/lib64:/opt/cray/rca/2.2.20-7.0.3.1_3.15__g8e3fb5b.ari/lib64:/opt/cray/pe/pmi/5.0.17/lib64:/opt/cray/pe/libsci/20.09.1/GNU/8.1/x86_64/lib:/apps/daint/UES/jenkins/7.0.UP03/21.09/daint-gpu/software/graphviz/2.50.0-CrayGNU-21.09/lib:/opt/cray/pe/libsci_acc/20.10.1/GNU/8.1/x86_64/lib:/apps/daint/UES/jenkins/7.0.UP03/21.09/daint-gpu/software/Julia/1.6.3-CrayGNU-21.09-cuda/lib:/opt/python/3.9.4.1/lib:/opt/cray/pe/gcc-libs:/opt/cray/pe/papi/6.0.0.9/lib64:/opt/gcc/9.3.0/snos/lib64\n",
       "2022-10-12 10:29:51.342831: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/daint/UES/6.0.UP04/sandboxes/sarafael/software/cuDNN/8.1.0/lib:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/compat:/usr/local/cuda-11.3/compat:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/math_libs/11.3/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/extras/CUPTI/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/extras/Debugger/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/nvvm/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/21.5/cuda/11.3/lib64:/usr/local/cuda-11.0/lib64:/opt/cray/pe/mpt/7.7.18/gni/mpich-gnu/8.2/lib:/opt/cray/pe/perftools/21.09.0/lib64:/opt/cray/rca/2.2.20-7.0.3.1_3.15__g8e3fb5b.ari/lib64:/opt/cray/pe/pmi/5.0.17/lib64:/opt/cray/pe/libsci/20.09.1/GNU/8.1/x86_64/lib:/apps/daint/UES/jenkins/7.0.UP03/21.09/daint-gpu/software/graphviz/2.50.0-CrayGNU-21.09/lib:/opt/cray/pe/libsci_acc/20.10.1/GNU/8.1/x86_64/lib:/apps/daint/UES/jenkins/7.0.UP03/21.09/daint-gpu/software/Julia/1.6.3-CrayGNU-21.09-cuda/lib:/opt/python/3.9.4.1/lib:/opt/cray/pe/gcc-libs:/opt/cray/pe/papi/6.0.0.9/lib64:/opt/gcc/9.3.0/snos/lib64\n",
       "2022-10-12 10:29:51.342844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
       "/apps/daint/UES/6.0.UP04/sandboxes/sarafael/hpcpython2022/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
       "  from .autonotebook import tqdm as notebook_tqdm\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributed as dist\n",
    "import tensorflow as tf\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torchvision import models\n",
    "from pt_distr_env import DistributedEnviron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab170ac-62d3-460d-bf88-aa4da966cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "tfrec_files = glob.glob(f'/scratch/snx3000/datasets/imagenet/ILSVRC2012_1k//train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98464f6a-c2ad-46b4-8a93-7dca2ac1660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "tf.config.set_visible_devices(\n",
    "    tf.config.list_physical_devices('CPU')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725b6266-cbf2-469f-ba5c-68fe664353a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stderr:0] [W socket.cpp:401] [c10d] The server socket cannot be initialized on [::]:39591 (errno: 97 - Address family not supported by protocol).\n",
       "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [nid03206]:39591 (errno: 97 - Address family not supported by protocol).\n",
       "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [nid03206]:39591 (errno: 97 - Address family not supported by protocol).\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stderr:1] [W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [nid03206]:39591 (errno: 97 - Address family not supported by protocol).\n",
       "[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [nid03206]:39591 (errno: 97 - Address family not supported by protocol).\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "distr_env = DistributedEnviron()\n",
    "dist.init_process_group(backend=\"nccl\")\n",
    "world_size = dist.get_world_size()\n",
    "rank = dist.get_rank()\n",
    "device = distr_env.local_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3510ac1a-ede0-4718-9c03-bd8a6701a6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddfe08a9-59a5-4fdb-b384-79f982319de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "def decode(serialized_example):\n",
    "    \"\"\"Decode and resize\"\"\"\n",
    "    example = tf.io.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "            'image/class/label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "    image = tf.image.decode_jpeg(example['image/encoded'], channels=3)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 224, 224)\n",
    "    image = tf.transpose(image, (2, 0, 1)) # rgb channels to the front\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    label = example['image/class/label'] - 1  # -> [0-999]\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfd0b11b-4c01-4514-aa6e-945636da78f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stderr:0] 2022-10-12 10:30:09.928024: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
       "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stderr:1] 2022-10-12 10:30:09.929858: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
       "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "dataset = tf.data.TFRecordDataset(tfrec_files)\n",
    "dataset = dataset.map(decode, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "dataset = dataset.shard(world_size, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40b97283-e7a1-4a4f-a996-d78e82eb5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "dataset_np = tfds.as_numpy(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fd1a310-7d59-44ea-be87-926f318c983e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stderr:0] libibverbs: Could not locate libibgni (/usr/lib64/libibgni.so.1: undefined symbol: verbs_uninit_context)\n",
       "libibverbs: Warning: couldn't open config directory '/opt/cray/rdma-core/27.1-7.0.3.1_4.6__g4beae6eb.ari/etc/libibverbs.d'.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stderr:1] libibverbs: Could not locate libibgni (/usr/lib64/libibgni.so.1: undefined symbol: verbs_uninit_context)\n",
       "libibverbs: Warning: couldn't open config directory '/opt/cray/rdma-core/27.1-7.0.3.1_4.6__g4beae6eb.ari/etc/libibverbs.d'.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "_model = models.resnet50()\n",
    "_model.to(device);\n",
    "\n",
    "ddp_model = DistributedDataParallel(_model, device_ids=[device])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8706059-a638-4416-98dd-be9f91f0003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "optimizer = optim.SGD(ddp_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da55873c-a2ac-4e31-b0ec-f7ef4d8ad4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "def benchmark_step(model, imgs, labels):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(imgs)\n",
    "    loss = F.cross_entropy(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca51853a-dffa-437d-9656-d739429820a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:1] \n",
       " * Epoch  0: 142.36 images/sec per GPU\n",
       " * Epoch  1: 196.43 images/sec per GPU\n",
       " * Epoch  2: 195.52 images/sec per GPU\n",
       " * Epoch  3: 195.78 images/sec per GPU\n",
       " * Epoch  4: 197.07 images/sec per GPU\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] \n",
       " * Epoch  0: 142.42 images/sec per GPU\n",
       " * Epoch  1: 196.55 images/sec per GPU\n",
       " * Epoch  2: 195.48 images/sec per GPU\n",
       " * Epoch  3: 195.79 images/sec per GPU\n",
       " * Epoch  4: 197.01 images/sec per GPU\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "print()\n",
    "num_epochs = 5\n",
    "num_iters = 10\n",
    "imgs_sec = []\n",
    "for epoch in range(num_epochs):\n",
    "    t0 = time.time()\n",
    "    for step, (imgs, labels) in enumerate(dataset_np):\n",
    "        if step > num_iters:\n",
    "            break\n",
    "\n",
    "        imgs = torch.from_numpy(imgs).to(device)\n",
    "        labels = torch.from_numpy(labels).to(device)\n",
    "        benchmark_step(ddp_model, imgs, labels)\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    imgs_sec.append(batch_size * num_iters / dt)\n",
    "\n",
    "    print(f' * Epoch {epoch:2d}: '\n",
    "          f'{imgs_sec[epoch]:.2f} images/sec per GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32cbf036-f2ec-4656-9a71-d117949fef87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPCluster stopped.\n"
     ]
    }
   ],
   "source": [
    "%ipcluster stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45257a0a-5f85-42fa-8828-159753c8cb73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2022",
   "language": "python",
   "name": "pytorch2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
