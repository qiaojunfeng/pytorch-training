{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0832b5a4-27a5-467d-84cb-5de56361336b",
   "metadata": {},
   "source": [
    "# Basic training of a CNN on imagenet from tfrecord files using NVidia DALI\n",
    "\n",
    "Here we will run a simplified training loop for a CNN model on ImageNet. We will create an [NVidia DALI](https://docs.nvidia.com/deeplearning/dali/user-guide/docs/index.html) input pipeline based on the [tfrecord](https://docs.nvidia.com/deeplearning/dali/user-guide/docs/operations/nvidia.dali.fn.readers.tfrecord.html#nvidia-dali-fn-readers-tfrecord) reader to read the ImageNet dataset stored in tfrecord files. Here we will make the input pipeline use bothe the cpu and gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2363679-29a4-402d-bc2c-9cd31fe0944f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/daint/UES/6.0.UP04/sandboxes/sarafael/hpcpython2022/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "import nvidia.dali.tfrecord as tfrec\n",
    "from torchvision import models\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "from nvidia.dali.plugin.pytorch import DALIClassificationIterator, LastBatchPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab170ac-62d3-460d-bf88-aa4da966cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/scratch/snx3000/datasets/imagenet/ILSVRC2012_1k/'\n",
    "\n",
    "tfrec_files = sorted(glob.glob(f'{data_dir}/train/*'))\n",
    "index_files = sorted(glob.glob(f'{data_dir}/idx_files/train/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92dee6df-82f4-4f08-babb-94bf62ea2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "pipe = Pipeline(batch_size=batch_size,\n",
    "                num_threads=12,\n",
    "                device_id=0)\n",
    "\n",
    "with pipe:\n",
    "    example = fn.readers.tfrecord(\n",
    "        path=tfrec_files,\n",
    "        index_path=index_files,\n",
    "        features={\n",
    "            'image/encoded': tfrec.FixedLenFeature((), tfrec.string, ''),\n",
    "            'image/class/label': tfrec.FixedLenFeature((), tfrec.int64, -1),\n",
    "        },\n",
    "        # read_ahead=True  # seems causing some troubles\n",
    "    )\n",
    "    label = example['image/class/label'] - 1\n",
    "    image = fn.decoders.image(example['image/encoded'], device='mixed', output_type=types.RGB)\n",
    "    image = fn.resize(image, device='gpu', size=(224, 224), dtype=types.FLOAT)\n",
    "    image = fn.transpose(image, perm=(2, 0, 1))\n",
    "    pipe.set_outputs(image.gpu(), label.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0d3188-028c-4b81-b141-5e3d8f09c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed224b6-fc13-4472-968b-fe1954ab2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DALIClassificationIterator(\n",
    "    pipe,\n",
    "    last_batch_padded=False,\n",
    "    auto_reset=True,\n",
    "    last_batch_policy=LastBatchPolicy.DROP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fd1a310-7d59-44ea-be87-926f318c983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "\n",
    "model = models.resnet50()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8706059-a638-4416-98dd-be9f91f0003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da55873c-a2ac-4e31-b0ec-f7ef4d8ad4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_step(model, imgs, labels):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(imgs)\n",
    "    loss = F.cross_entropy(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca51853a-dffa-437d-9656-d739429820a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Epoch  0: 177.55 images/sec per GPU\n",
      " * Epoch  1: 216.81 images/sec per GPU\n",
      " * Epoch  2: 188.60 images/sec per GPU\n",
      " * Epoch  3: 202.28 images/sec per GPU\n",
      " * Epoch  4: 201.57 images/sec per GPU\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "num_iters = 10\n",
    "imgs_sec = []\n",
    "for epoch in range(num_epochs):\n",
    "    t0 = time.time()\n",
    "    for step, samples in enumerate(train_loader):\n",
    "        if step > num_iters:\n",
    "            break\n",
    "        \n",
    "        imgs = samples[0]['data']\n",
    "        labels = samples[0]['label']\n",
    "        benchmark_step(model, imgs, labels)\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    imgs_sec.append(batch_size * num_iters / dt)\n",
    "\n",
    "    print(f' * Epoch {epoch:2d}: '\n",
    "          f'{imgs_sec[epoch]:.2f} images/sec per GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd242f1d-10f5-46ac-9a71-17882621fc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2022",
   "language": "python",
   "name": "pytorch2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
